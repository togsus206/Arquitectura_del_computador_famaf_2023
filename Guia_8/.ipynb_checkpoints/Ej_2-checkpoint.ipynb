{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Nb37sCEKIG"
      },
      "source": [
        "# Código Ejercicio 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNjRTw0LhRWD",
        "outputId": "83fbed2a-819e-4aaa-d6f2-31a934e36b8d"
      },
      "source": [
        "!pip install pyopencl\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "import pyopencl as cl\n",
        "import pyopencl.array as cl_array\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyopencl\n",
            "  Downloading pyopencl-2022.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (934 kB)\n",
            "\u001b[K     |████████████████████████████████| 934 kB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.21.6)\n",
            "Collecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting pytools>=2021.2.7\n",
            "  Downloading pytools-2022.1.12.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2021.2.7->pyopencl) (4.1.1)\n",
            "Building wheels for collected packages: pytools\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.12-py2.py3-none-any.whl size=65034 sha256=854f9ec0b761e175d5a75c0697b84e80964c680e32abbad6de605e38f410882b\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/5e/9e/76d7430e116b7cab0016fbabb26b896daae1946a3f7dea9915\n",
            "Successfully built pytools\n",
            "Installing collected packages: platformdirs, pytools, pyopencl\n",
            "Successfully installed platformdirs-2.5.2 pyopencl-2022.2.4 pytools-2022.1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUmn4ggbFyFv",
        "outputId": "0cc6af25-87d2-4808-8a65-dd169885b9db"
      },
      "source": [
        "!lscpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               85\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "Stepping:            3\n",
            "CPU MHz:             2000.152\n",
            "BogoMIPS:            4000.30\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            1024K\n",
            "L3 cache:            39424K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Wed Nov  2 13:36:15 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYKKyzkkGz5Y"
      },
      "source": [
        "## Kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5U5p18VGCp8"
      },
      "source": [
        "KernelSource = \"\"\"\n",
        "__kernel void parallelMMult(\n",
        "  const int N,\n",
        "  __global const float *a_g,\n",
        "  __global const float *b_g,\n",
        "  __global float *res_g)\n",
        "  {\n",
        "    int i = get_global_id(0);\n",
        "    int j = get_global_id(1);\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    for(int k = 0; k < N; k++) {\n",
        "      sum += a_g[i*N + k] * b_g[k*N + j];\n",
        "    }\n",
        "    //barrera\n",
        "    res_g[i*N + j] = sum;\n",
        "\n",
        "  }\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9FYnO62IP42"
      },
      "source": [
        "## Host"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7R-Q4mxIPfa",
        "outputId": "8426fd5d-4e21-43f7-fa57-8c5a9d6cf937"
      },
      "source": [
        "N = 2500\n",
        "\n",
        "# Obtener la plataforma\n",
        "plataform_list = cl.get_platforms()\n",
        "\n",
        "# Obtener los dispositivos\n",
        "devices = plataform_list[0].get_devices(device_type = cl.device_type.GPU)\n",
        "\n",
        "# Crear el contexto\n",
        "context = cl.Context(devices=devices)\n",
        "\n",
        "# Crear el Command Queue\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "# Crear e inicializar los vectores de entrada\n",
        "a_np = np.arange(N*N).astype(np.float32)\n",
        "b_np = np.arange(N*N).astype(np.float32)\n",
        "\n",
        "# Crear e inicializar el vector de salida\n",
        "res_np = np.empty_like(a_np)\n",
        "\n",
        "# Crear e inicializar los Buffers (OpenCL)\n",
        "a_g = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf = a_np)\n",
        "b_g = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf = b_np)\n",
        "\n",
        "# Crear buffer de salida (OpenCL)\n",
        "res_g = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, res_np.nbytes)\n",
        "\n",
        "# Crear el programa\n",
        "program = cl.Program(context, KernelSource).build()\n",
        "\n",
        "# Crear el kernel\n",
        "kernel = program.parallelMMult\n",
        "\n",
        "# Configurar los argumentos\n",
        "kernel.set_scalar_arg_dtypes([np.int32, None, None, None])\n",
        "kernel.set_args(N, a_g, b_g, res_g)\n",
        "\n",
        "# Definir el espacio indexado\n",
        "globalRange = (N,N)\n",
        "localRange = None\n",
        "\n",
        "# Ejecutar el kernel\n",
        "ev = cl.enqueue_nd_range_kernel(queue, kernel, globalRange, localRange)\n",
        "\n",
        "# Copy result del device al host\n",
        "cl.enqueue_copy(queue, res_np, res_g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyopencl._cl.NannyEvent at 0x7fdec81bbfb0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-LUj_c4N99A",
        "outputId": "95df9a00-a8bc-40b3-d580-3ed308feb1ba"
      },
      "source": [
        "np_matmul = np.matmul(a_np.reshape(N,N),b_np.reshape(N,N))\n",
        "\n",
        "print(res_np.reshape(N,N))\n",
        "\n",
        "print(np_matmul)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.3013013e+13 1.3013016e+13 1.3013018e+13 ... 1.3020832e+13\n",
            "  1.3020833e+13 1.3020835e+13]\n",
            " [3.2536474e+13 3.2536479e+13 3.2536493e+13 ... 3.2559845e+13\n",
            "  3.2559853e+13 3.2559866e+13]\n",
            " [5.2059865e+13 5.2059877e+13 5.2059894e+13 ... 5.2098918e+13\n",
            "  5.2098926e+13 5.2098939e+13]\n",
            " ...\n",
            " [4.8762993e+16 4.8763014e+16 4.8763027e+16 ... 4.8801974e+16\n",
            "  4.8801987e+16 4.8802004e+16]\n",
            " [4.8782556e+16 4.8782574e+16 4.8782591e+16 ... 4.8821542e+16\n",
            "  4.8821559e+16 4.8821576e+16]\n",
            " [4.8802081e+16 4.8802098e+16 4.8802111e+16 ... 4.8841092e+16\n",
            "  4.8841105e+16 4.8841118e+16]]\n",
            "[[1.3013021e+13 1.3013023e+13 1.3013025e+13 ... 1.3020823e+13\n",
            "  1.3020825e+13 1.3020826e+13]\n",
            " [3.2536458e+13 3.2536466e+13 3.2536474e+13 ... 3.2559866e+13\n",
            "  3.2559877e+13 3.2559887e+13]\n",
            " [5.2059894e+13 5.2059915e+13 5.2059932e+13 ... 5.2098910e+13\n",
            "  5.2098926e+13 5.2098943e+13]\n",
            " ...\n",
            " [4.8763036e+16 4.8763053e+16 4.8763066e+16 ... 4.8802013e+16\n",
            "  4.8802025e+16 4.8802043e+16]\n",
            " [4.8782561e+16 4.8782574e+16 4.8782595e+16 ... 4.8821555e+16\n",
            "  4.8821568e+16 4.8821585e+16]\n",
            " [4.8802081e+16 4.8802098e+16 4.8802111e+16 ... 4.8841097e+16\n",
            "  4.8841110e+16 4.8841127e+16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_np.reshape(N,N))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xALrvod9jyoA",
        "outputId": "311f220c-a3aa-474c-e432-20e7222f594a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.  1.  2.  3.  4.]\n",
            " [ 5.  6.  7.  8.  9.]\n",
            " [10. 11. 12. 13. 14.]\n",
            " [15. 16. 17. 18. 19.]\n",
            " [20. 21. 22. 23. 24.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mO7hV2tYj42i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}